\include{header}
\begin{document}

\chapter{Introduction} \label{chap:Intro}

Holography has two basic methods of obtaining holograms, in-line holography and
off-axis holography. There are different types of those techniques, but those
are the two broad categories in which holography can be situated into.
Holography was invented by Dennis Gabor in 1948, and he developed the technique
of the in-line holography. Later, in 1960, Emmett N. Leith and Juris Upatnieks developed
off-axis holography.
A hologram is a coherent addition of two light fields, which produces an
interference pattern. This interference pattern contains all of the information
of the object that is being recorded, and can be reconstructed with this
information.
PAGE 469 of GUENTHERE


%
%
%Different methods to obtain a hologram: These are all basically all the
%different optical systems that can be used to obtain a hologram.  This list is
%not extensive.
%
%\begin{itemize} \item in-line (Gabor) holograms - This is the optical system in
%            which the object is illuminated by a collimated beam of
%            monochromatic light along an axis normal to the photographic plate.
%            (Basics of Holography- P. Hariharan)
%
%    \item off-axis (Leiths-Upatnieks) holograms - In this optical system, the
%        source beam is split, and half of the beam is used as a reference beam,
%        and goes directly to the photographic plate. The other half of the beam
%        is directed to the object and then to the photographic plate.  \item
%            fourier holograms -
%
%    \item lenless-fourier holograms \item image holograms gets a only the real
%    image of the object \item reflection holograms
%
%
%\end{itemize}
%
%Different types of holograms:
%
%\begin{itemize} \item thin  and thick holograms come about when looking at the
%            thickness of the recording medium.  If the thickness of the
%            recording medium is larger than the average spacing of the fridges,
%            then volume effects cannot be neglected. For our purposes, the CCD
%            camera is a thin recording medium I believe.  If $Q<1$ then it's a
%            thin grating, else its a thick grating, where Q is \begin{equation}
%                Q=2\pi\lambda_{0}d/n_{0}\Lambda^2 \label{Q} \end{equation}
%
%    \item volume transmission \item volume reflection \item digital holograms
%    \item pinhole holograms \item Fraunhofer holograms
%
%\end{itemize}

\section{Fresnel-Kirchoff Integral}

The diffraction of a light wave at an aperature which is fastened perpendicular
to the incoming beam is described by the Fresnel-Kirchoff integral:

\begin{equation}
    \Gamma(\xi,\eta) =
    \frac{1}{\lambda}\int_{-\infty}^{\infty}\int_{-\infty}^{\infty}h(x,y)R(x,y)\frac{\exp\left(
        -i\frac{2\pi}{\lambda} \right)\rho}{\rho}\times \left(
        \frac{1}{2}+\frac{1}{2}\cos\theta \right)~dx~dy
        \label{fresnel-kirchoff}
    \end{equation}
    with

    \begin{equation}
        \rho = \sqrt{(x-\xi)^{2}+(y-\eta)^{2}+d^{2}}
    \end{equation}
    where $h(x,y)$ is the hologram function, $R(x,y)$ is the reference wave
    function, $\rho$ is the distance between a point in the hologram plane and
    a point in the reconstruction plane, and $d$ is the distance from the hologram
    to the image plane. If a plane wave reference wave is used,
    then $R(x,y)$ is given by the real amplitude:

    \begin{equation}
        R = r+ i0 = r
    \end{equation}

    If the values of $x$ and $y$ along with the values of $\xi$ and $\eta$ are
    small compared the the distance between the planes, $d$, then $\rho$ can be
    replaced with a Taylor series approximated to the first terms:

    \begin{equation}
        \rho=d+\frac{(\xi-x)^{2}}{2d}+\frac{(\eta-y)^{2}}{2d}-\frac{1}{8}\frac{\left[
        (\xi-x)^{2}+(\eta-y)^{2} \right]}{d^{3}} + \cdots
    \end{equation}

    \begin{equation}
        \rho\approx d+\frac{(\xi-x)^{2}}{2d}+\frac{(\eta-y)^{2}}{2d}
    \end{equation}

    Using this, along with a small angle approximation, the Fresnel-Kirchoff
    integral can be simplified to

    \begin{multline}
        \Gamma(\xi,\eta) = \frac{i}{\lambda d} \exp\left( -i\frac{2\pi}{\lambda}d \right)
        \int_{-\infty}^{\infty}\int_{-\infty}^{\infty}h(x,y)R(x,y) \\
        \times \exp\left[ -i\frac{\pi}{\lambda d}\left(
        (\xi-x)^{2}+(\eta-y)^{2} \right) \right]~dx~dy
    \end{multline}

    \begin{multline}
        \Gamma(\xi,\eta) = \frac{i}{\lambda d} \exp\left( -i\frac{2\pi}{\lambda}d \right)
        \exp\left[ -i\frac{\pi}{\lambda d}(\xi^2+\eta^2) \right] \\
        \int_{-\infty}^{\infty}\int_{-\infty}^{\infty}h(x,y)R(x,y)
        \exp\left[ -i\frac{\pi}{\lambda d}\left(
        x^{2}+y^{2} \right) \right]
        \exp\left[ i\frac{2\pi}{\lambda d}\left(
        x\xi+y\eta \right) \right]~dx~dy
    \end{multline}

    The intensity is simply the magnitude of the reconstruction squared.

    \begin{equation}
        I(\xi,\eta) = |\Gamma(\xi,\eta)|^{2}
    \end{equation}

    and the phase can be calculated by
    \begin{equation}
        \phi(\xi,\eta)=\arctan\left( \frac{\mathrm{Im}[\Gamma(\xi,\eta)]}{\mathrm{Re}[\Gamma(\xi,\eta)]} \right)
    \end{equation}
    where Re and Im correspond to the real and the imaginary parts of the
    reconstruction respectively.

    To digitize these equations, we introduce a transformation of

    \begin{equation}
        \nu = \frac{\xi}{\lambda d} \qquad \mu = \frac{\eta}{\lambda d}
    \end{equation}

    \begin{multline}
        \Gamma(\nu,\mu) = \frac{i}{\lambda d} 
        \exp\left[ -i\pi\lambda d(\nu^2+\mu^2) \right] \\
        \int_{-\infty}^{\infty}\int_{-\infty}^{\infty}h(x,y)R(x,y)
        \exp\left[ -i\frac{\pi}{\lambda d}\left(
        x^{2}+y^{2} \right) \right]
        \exp\left[ i2\pi\left(
        x\nu+y\mu \right) \right]~dx~dy
    \end{multline}

    It can be seen from this equation, that the Fresnel approximation is the
    inverse Fourier transformation.

    \begin{align}
        \Gamma(\nu,\mu)&=\frac{i}{\lambda d}\exp\left[ -i\pi\lambda d\left(
            \nu^2+\mu^2
        \right) \right] \\
        & \mathfrak{F}^{-1}\left\{R(x,y)h(x,y)\exp\left[
            -i\frac{\pi}{\lambda d}(x^{2}+y^2)
        \right] \right\}
    \end{align}

    If the hologram function is sampled on a rectangular raster of $N\times $
    points, with steps between neighbouring pixels on the CCD being $\Delta x$ and $\Delta
    y$ in the horizontal and vertical directions respectivel, then the
    integrals can be converted into finite sums using these discrete values:

    \begin{align}
        \Gamma(m,n) &= \frac{i}{\lambda d}\exp\left[ -i\pi \lambda d\left(
            m^2\Delta \nu^2 + n^2\Delta \mu^2
        \right)\right]\\
        & \times
        \sum_{k=0}^{N-1}\sum_{k=0}^{N-1}R(k,l)h(k,l)\exp\left[ -i
        \frac{\pi}{\lambda d}\left( k^2\Delta x^2+l^2\Delta y^2 \right)
    \right] \\
    & \times \exp\left[ i2\pi\left( k\Delta x m \Delta\nu+l\Delta y n
    \Delta\mu \right) \right]
    \end{align}
    According to the theory of Fourier transform among $\Delta x$, $\Delta y$
    and $\Delta\nu$, and $\Delta\mu$ the following relation exist:

    \begin{equation}
        \Delta\nu=\frac{1}{N\Delta x}; \qquad \Delta\mu=\frac{1}{N\Delta y}
    \end{equation}
    Now substituting our original variables back in:

    \begin{equation}
        \Delta\xi=\frac{\lambda d}{N\Delta x}; \qquad \Delta\eta=\frac{\lambda
        \lambda d}{N\Delta y}
    \end{equation}
    Plugging this back in,

    \begin{align}
        \Gamma(m,n) & = \frac{i}{\lambda d}\exp\left[ -i\pi \lambda d\left(
            \frac{m^2}{N^2\Delta x^2}+\frac{n^2}{N^2\Delta y^2}
        \right)\right]\\
        &\times
        \sum_{k=0}^{N-1}\sum_{k=0}^{N-1}R(k,l)h(k,l)\exp\left[ -i
        \frac{\pi}{\lambda d}\left( k^2\Delta x^2+l^2\Delta y^2 \right)
    \right] \\
    &\times \exp\left[ i2\pi\left( \frac{km}{N}+\frac{ln}{N} \right) \right]
    \end{align}
    This is a discrete Fresnel transform, and it is calculated by multiplying
    $R(k,l)$ with $h(k,l)$ and $\exp\left[ -i
        \frac{\pi}{\lambda d}\left( k^2\Delta x^2+l^2\Delta y^2 \right)
    \right]$
    and then applying an inverse Fourier transform to the product. This is done
    the most effectively using the fast Fourier transform, or FFT\@. The factor
    in front of the sum is only affecting the phase and can be neglected for
    most applications.


        \section{Fourier Transform}

        In science, one of the most fundamental principles is the superposition
        principle. The superposition principle tells us that for a linear system
        composed of different functions is the sum of the responses that would have
        been caused by the different functions individually. Green's function is
        written as the
        superposition of infinitely many impulse response functions, which then makes
        the response a superposition of impulse responses. Fourier transforms are like
        Green's function, but instead of using impulse response functions, it uses
        sinusoids instead.

        Think of sinusoids (sines and cosines) as being the fundamental building blocks
        for functions. From these functions, we can write any other function as a
        superposition of those two functions, whether they be periodic or not. This can
        be represented with an infinite series, known as the Fourier series.

        First, let's suppose that $f(t)$ is a periodic function with a period
        $T$, so that
        \begin{equation}
            f(t)=f(t+T)
        \end{equation}
        for all values of $t$. We can represent this as

        \begin{equation}
            f(t) = a_0 + b_0 + 2\sum_{n=1}^{\infty} a_n \cos(n\omega
            t)+2\sum_{n=1}^{\infty}b_n\sin(n\omega t)
            \label{eq:fourierseries}
        \end{equation}
        where $\omega=2\pi\nu=\frac{2\pi}{T}$ is the angular frequency, and $\nu$ is the frequency.
        We can define the complex Fourier coefficient as

        \begin{equation}
            c_n \equiv a_n+ib_n
        \end{equation}
        which allows for Equation~\ref{eq:fourierseries} to be rewritten as

        \begin{equation}
            f(t) = a_0 + b_0 +\sum_{n=1}^{\infty} a_n \left( e^{in\omega t} +
            e^{-in\omega t} \right) - i\sum_{n=1}^{\infty} b_n \left( e^{in\omega t} -
            e^{-in\omega t} \right)
        \end{equation}
        This can be simplified farther

        \begin{equation}
            f(t) = \sum_{n=-\infty}^{\infty}a_ne^{-in\omega t} + i\sum_{n=-\infty}^{\infty}b_ne^{-in\omega t}
        \end{equation}

        Now, using the complex Fourier coefficient defined earlier, we can get the
        complex Fourier series:

        \begin{equation}
            f(t)=\sum_{n=-\infty}^{\infty}c_ne^{-in\omega t}
        \end{equation}

        Now, these same harmonic functions can be used to build aperiodic functions. An
        aperiodic function corresponds to $T\rightarrow \infty$, so we need a
        continuous spectrum to represent an aperiodic function, since there is more
        information in the function than the aperiodic case.

        \begin{equation}
            f(t)=\sum_{n=-\infty}^{\infty}c_ne^{-in\omega t} \rightarrow
            f(t)=\frac{1}{2\pi}\int_{-\infty}^{\infty} \tilde{f}(\omega) e^{-i\omega t}~d\omega
        \end{equation}
        This is the inverse Fourier transform. To find the amplitudes, $c_n$, which are
        also called the Fourier transform,

        \begin{equation}
            c_n = \frac{1}{T}\int_0^Te^{in\omega t} f(t) dt \rightarrow
            \tilde{f}(\omega) =\int_{-\infty}^{\infty}f(t)e^{i\omega t}~dt
        \end{equation}
        In a more common notation,

        \begin{equation}
            \mathfrak{F} =\int_{-\infty}^{\infty}f(t)e^{i\omega t}~dt
            \qquad
            \mathfrak{F}^{-1} =\int_{-\infty}^{\infty}f(\omega)e^{-i\omega t}~d\omega
        \end{equation}
        where $\mathfrak{F}$ is the Fourier transform of  $f(t)$ and
        $\mathfrak{F}^{-1}$ is the inverse Fourier transform of $f(t)$.


%*=============================================================================================*

        \section{Fast Fourier Transform (FFT)}

        The most commonly used FFT algorithm is known as the Cooley-Tukey algorithm.
        This is a recursive algorithm, and the basic idea is to take a DFT and split it
        into smaller DFTs. For example, taking a $n$ size DFT and transforming it into
        two DFTs of size $n_1$ and $n_2$ respectively.

        The discrete Fourier transform of an array $X$ with $n$ complex numbers is the array
        $Y$ given by

        \begin{equation}
            Y[k] = \sum_{j=0}^{n-1}X[j]\omega_n^{jk}
            \label{eq:dft}
        \end{equation}
        where $0\le k < n$ and $\omega_n=\exp\left( -2\pi\sqrt{-1}/n \right)$.
        $\omega_n$ is known as the twiddle factor. The problem
        with the DFT is that it requires \BigO{n^{2}} operations.

        The Cooley-Tukey algorithm can be derived from Equation~\ref{eq:dft}. If
        $n$ can be factored into $n=n_1n_2$, then we can rewrite
        Equation~\ref{eq:dft}
        letting $j=j_1n_2+j_2$ and $k=k_1+k_2n_2$.

        \begin{equation}
            Y[k_1+k_2n_2]=\sum_{j_2=0}^{n_2-1}\left[ \left( \sum_{j_1=0}^{n_1-1}
                X[j_1n_2+j_2]w_{n_1}^{j_1k_1} \right)w_n^{j_2k_1} \right]w_{n_2}^{j_2k_2}
            \end{equation}


            Fast Fourier transforms,
            have \BigO{n \log n} operations, which is much better
            computationally than the DFT's \BigO{n^2} operations. This difference is more clearly shown in
            Figure~\ref{fig:dftVSfft}, which only shows up to $n=20$, yet, the difference is
            already about a factor of 8 operations.

            \begin{figure}[htbp!]
                \begin{center}
                    \includegraphics[scale=0.5]{dftVSfft}
                \end{center}
                \caption{Shown here is the difference between \BigO{n^2} operations and
                \BigO{n\log n} operations.}
                \label{fig:dftVSfft}
            \end{figure}

            The Cooley-Tukey algorithm computes $n_2$ DFTs of size $n_1$, multiples the
            result by the twiddle factors, and finally computes $n_1$ DFTs of size
            $n_2$. This decomposition is then continued recursively. A term that comes up a
            lot in FFT is the radix, which is used to describe an $n_1$ or $n_2$ that is
            bounded. The small DFT of the radix is traditionally called a butterfly. The
            Cooley-Tukey algorithm also rearranges the DFT of $X$ into a sum over the even
            and odd indices.
            For example, if $n=8$, and a radix-2 algorithm was used, then it would split it
            into $n_1=4$ and $n_2=4$. The algorithm would then split the data into many
            size-2 DFTs called butterfly operations. Figure~\ref{fig:radix-2} shows this
            process.

%        \begin{figure}[htbp!]
%            \begin{center}
%                \includegraphics[scale=0.5]{radix-2}
%            \end{center}
%            \caption{An example of $n=8$, radix-2 FFT.}
%            \label{fig:radix-2}
%        \end{figure}

            \begin{figure}[htbp!]
                \begin{center}
                    \includegraphics[scale=0.75]{radix-2.pdf}
                \end{center}
                \caption{An example of $n=8$, radix-2 FFT.}
                \label{fig:radix-2}
            \end{figure}

            The Cooley-Tukey algorithm isn't without it's own problems. The main problem is
            that the $n_1$ dimension corresponds to discontiguous inputs $j_1$ in
            $X$, but contiguous outputs in $k_1$ in $Y$, and vice versa for $n_2$.
            This is a matrix transpose for a single decomposition stage, and the
            composition of all such transpositions is a digit-reversal permutation
            (or, bit reversal for radix-2). The contiguous and discontiguous
            operations are better shown in Figure~\ref{fig:DFT2D}. The result of the discontiguous memory
            access and data reordering  hinders the efficient use of hierarchical memory
            architectures efficiencies (cache). The bit reversal technique is shown
            in Table~\ref{tab:bitreversal}.

            \begin{figure}[htbp!]
                \begin{center}
                    \includegraphics[scale=0.5]{DFT2D}
                \end{center}
                \caption{Another diagram of how a DFT works, showing contiguous and
                non-contiguous operations.}
                \label{fig:DFT2D}
            \end{figure}

            \begin{table}[htbp!]
                \begin{center}
                    \caption{Bit reversal done on the indices of an array.}
                    \label{tab:bitreversal}
                    \begin{tabular}{|c|c|c|c|}
                        \hline
                        index & binary & bit reversal & bit rev.\ index \\
                        \hline
                        0 & 000 & 000 & 0 \\
                        1 & 001 & 100 & 4 \\
                        2 & 010 & 010 & 2 \\
                        3 & 011 & 110 & 6 \\
                        4 & 100 & 001 & 1 \\
                        5 & 101 & 101 & 5 \\
                        6 & 110 & 011 & 3 \\
                        7 & 111 & 111 & 7 \\
                        \hline
                    \end{tabular}
                \end{center}
            \end{table}



            \section{Convolution and the Convolution Theorem}

            The convolution is a mathematical operation that maps a pair of
            functions to a function. This can be defined as
            \begin{equation}
                (f*g)(x) \equiv \int_{-\infty}^{\infty} f(x')g(x-x')dx'
                \label{eq:convolution}
            \end{equation}
            If we allow $g(x')$ to be a localized function, then we call this a
            convolution kernel.
            This allows us to think of the convolution
            as the value at location $x$ is the amount of $f(x')$ that passes
            through $g(x')$ when $g$ is displaced by an amount $x$. For example,
            let $g(x) = \delta(x)$. The convolution with $f(x)$ is
            \begin{equation}
                (f*\delta)(x)=\int_{-\infty}^{\infty}f(x')\delta(x-x')dx'=f(x)
            \end{equation}
            The convolution gives us back the original function $f(x)$, and it
            does this because the $\delta$-function is a perfectly localized
            function. Now, if we displace the $\delta$-function by some amount, $g(x)=\delta(x-x_0)$,
            we get
            \begin{equation}
                (f*\delta)(x)=\int_{-\infty}^{\infty}f(x')\delta(x-x')dx'=f(x-x_0)
            \end{equation}

            Convolution can be very useful, but as has been discussed, doing an
            integral numerically can be slow, especially when you function, $f(x)$,
            is an image. The convolution theorem gives us a way to easy evaluate
            Equation~\ref{eq:convolution}. The convolution theorem states that the
            Fourier transform of the convolution is the product of the Fourier
            transforms of the individual functions:
            \begin{equation}
                \mathfrak{F}\left[ f*g
                \right]=\mathfrak{F}[f]\mathfrak{F}[g]
            \end{equation}
            This allows us to write the convolution as
            \begin{equation}
                f*g = \mathfrak{F}^{-1}\left\{\mathfrak{F}[f]\mathfrak{F}[g] \right\}
            \end{equation}
            Using this formulation of the convolution, we can use the FFT which is
            fast and efficient computationally, and allows us to easily process the
            convolution. The convolution theorem is of great use in numerically
            reconstructing holograms.

            DANIEL STECK PAGE 187-189


    \section{Reconstruction}

%    \emph{Skipping a bit here}
    Might want to move this to a reconstruction section, after all of the FFT
    stuff so it will make more sense.

    \begin{equation}
        \Gamma(\xi,\eta) = \int_{-\infty}^{\infty}\int_{-\infty}^{\infty}
        h(x,y)R(x,y) g(\xi,\eta,x,y)~dx~dy
        \label{eq:superpositionIntegral}
    \end{equation}
    where $g(\xi,\eta,x,y)$ is the impulse response function and is given by

    \begin{equation}
        g(\xi,\eta,x,y)=\frac{1}{\lambda}\frac{\exp\left[
        -i\frac{2\pi}{\lambda}\sqrt{d^{2}+(x-\xi)^{2}+(y-\eta)^{2}} \right]}{\sqrt{d^{2}+(x-\xi)^{2}+(y-\eta)^{2}}}
        \label{impulse}
    \end{equation}
    Once again, the small angle approximation was used. Equation~\ref{impulse}
    shows that the impulse response function is space-invariant, which allows the
    use of the convolution theorem. This means that we can rewrite
    Equation~\ref{eq:superpositionIntegral} with the Fourier transforms

    \begin{equation}
        \Gamma(\xi,\eta) = \mathfrak{F}^{-1}\left\{ \mathfrak{F}(R\cdot h)
        \cdot\mathfrak{F}(g) \right\}
        \label{eq:convReconstruction}
    \end{equation}

    The impulse response function is a delta function that is known to mathematicians as Green's function,
    and in optics it is known as the point spread function. The impulse response is
    a way of remembering past events. It is used as a weighting function in the
    convolution integral. The weighting function serves as a window through which a
    time average is performed. The window determines how much of the past history
    of the function can be seen when the time average is performed.
    GUENTHER 240-241

    The impulse response in 2D and in 3D are shown in Figure~\ref{fig:psf} and
    Figure~\ref{fig:psf3D} respectively.

    \begin{figure}[htbp!]
        \begin{center}
            \includegraphics[scale=0.5]{psf}
        \end{center}
        \caption{A 2D impulse response function.}
        \label{fig:psf}
    \end{figure}

    \begin{figure}[htbp!]
        \begin{center}
            \includegraphics[scale=0.25]{psf3D}
        \end{center}
        \caption{A 3D impulse response function generated from the 2D plot in
            Figure~\ref{fig:psf}.}
            \label{fig:psf3D}
        \end{figure}

    The numerical realization of the impulse response function is

    \begin{equation}
        g(k,l)=\frac{i}{\lambda}=\frac{\exp\left[
        -i\frac{2\pi}{\lambda}\sqrt{d^2+\left(k-\frac{N}{2}\right)^2\Delta x^2+\left(
        l-\frac{N}{2}
    \right)^{2}\Delta y^2} \right]}{\sqrt{d^2+\left(k-\frac{N}{2}\right)^2\Delta x^2+\left(
        l-\frac{N}{2}
    \right)^{2}\Delta y^2}}
    \end{equation}
    The Fourier transform of $g(k,l)$ can be calculated and expressed
    analytically:

    \begin{equation}
        G(n,m) = \exp\left\{ -i\frac{2\pi
        d}{\lambda}\sqrt{1-\frac{\lambda^{2}\left( n+\frac{N^2\Delta
        x^2}{2d\lambda} \right)^2}{N^2\Delta x^2}-\frac{\lambda^{2}\left( m+\frac{N^2\Delta
        y^2}{2d\lambda} \right)^2}{N^2\Delta y^2}} \right\}
    \end{equation}
    This saves one Fourier transformation for reconstruction, allowing for
    Equation~\ref{eq:convReconstruction} to be rewritten as

    \begin{equation}
        \Gamma(\xi,\eta) = \mathfrak{F}^{-1}\left\{ \mathfrak{F}(R\cdot h)
        \cdot G \right\}
        \label{eq:finalEquation}
    \end{equation}

    Equation~\ref{eq:finalEquation} is how HoloPy does reconstructions.



%*=============================================================================================*







\end{document} 
